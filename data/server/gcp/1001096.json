{
  "vendor_id": "gcp",
  "server_id": "1001096",
  "name": "a2-megagpu-16g",
  "api_reference": "a2-megagpu-16g",
  "display_name": "a2-megagpu-16g",
  "description": "Accelerator Optimized: 16 NVIDIA Tesla A100 GPUs, 96 vCPUs, 1360GB RAM",
  "family": "a2",
  "vcpus": 96,
  "hypervisor": null,
  "cpu_allocation": "DEDICATED",
  "cpu_cores": null,
  "cpu_speed": null,
  "cpu_architecture": "X86_64",
  "cpu_manufacturer": null,
  "cpu_family": null,
  "cpu_model": null,
  "cpu_l1_cache": null,
  "cpu_l2_cache": null,
  "cpu_l3_cache": null,
  "cpu_flags": [],
  "cpus": [],
  "memory_amount": 1392640,
  "memory_generation": null,
  "memory_speed": null,
  "memory_ecc": null,
  "gpu_count": 16,
  "gpu_memory_min": null,
  "gpu_memory_total": null,
  "gpu_manufacturer": null,
  "gpu_family": null,
  "gpu_model": "nvidia-tesla-a100",
  "gpus": [],
  "storage_size": 0,
  "storage_type": null,
  "storages": [],
  "network_speed": null,
  "inbound_traffic": 0.0,
  "outbound_traffic": 0.0,
  "ipv4": 0,
  "status": "ACTIVE"
}